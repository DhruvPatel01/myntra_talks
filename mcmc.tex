\documentclass[pdf]{beamer}
\usetheme{Warsaw}

\usepackage{amsmath}

\title{Monte Carlo Markov Chain methods}
\author{Dhruv Patel}
\institute{Myntra}
\date{\today}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\section{Markov Chains}
\begin{frame}
  \frametitle{Markov Chains}
  \begin{itemize}
  \item  Defined by transition probability $T_m(Z^m, Z^{m+1})$
  \item For time homogeneous chains $T_m$ is same for all $m$.
  \end{itemize}
\end{frame}

\begin{frame}{Markov Chains (cont)}
  \begin{block}{Stationary Distribution}
    A distribution $p$ is stationary with respect to Markov chain defined by transition probability $T$ if
    
    \[
      p(z) = \sum_{z'}T(z', z) p(z')
    \]
  \end{block}
\end{frame}

\begin{frame}{Detailed Balance}

  \begin{theorem}
    Given $p$, if we choose $T$ such that detailed balance equation is satisfied then $p$ will be stationary distribution for this $T$.
    
    \[
      p(z)T(z, z') = p(z')T(z', z)  
    \]
  \end{theorem}
  \begin{proof}
    \begin{align*}
      \sum_{z'} p(z') T(z', z) &= \sum_{z'} p(z) T(z, z')  && \text{by hypothesis} \\
                               &= p(z) \sum_{z'}T(z, z') \\
                               &= p(z)
    \end{align*}
  \end{proof}
\end{frame}

\section{MCMC Methods}
\subsection{Metropolis-Hastings Algorithm}

\begin{frame}{Metropolis-Hastings Algorithm}
  \begin{itemize}
  \item Generalizes Metropolis algorithm
  \item No need for proposal distribution to be symmetric
  \item Acceptance probability for proposal of $z^*$ from $z^\tau$

    \[
      A(z^*|z^\tau) = \text{min} \left( 1, \frac{\tilde{p}(z^*) q(z^\tau|z^*)}{\tilde{p}(z^\tau) q(z^*|z^\tau)} \right)
    \]

    Where $\tilde{p}(z)$ is the unnormalized density at $z$ and $q(z|z')$ is a proposal distribution at $z'$.
  \item Note that for symmetric $q$, this boils down to Metropolis algorithm
  \item Transition probability is given by

    \[
      T(z^\tau, z^*) = q(z^*|z^\tau) A(z^*| z^\tau)
    \]
    
  \end{itemize}
\end{frame}

\begin{frame}
  We will prove that our target distribution $p$ (i.e. normalized version of $\tilde{p}$) is stationary distribution with respect to transition probability defined in last slide by proving that it satisfies detailed balance condition. (detailed balance $\implies$ stationary distribution)

\end{frame}
\begin{frame}[shrink]
  \begin{proof}
    \begin{align*}
      p(z)T(z, z') &= p(z) q(z'|z) A(z'|z) \\
                   &= p(z) q(z'|z)  \text{min} \left( 1, \frac{\tilde{p}(z') q(z|z')}{\tilde{p}(z) q(z'|z)} \right) \\
                   &= \text{min} \left( p(z) q(z'|z) , p(z) q(z'|z) \frac{\tilde{p}(z') q(z|z')}{\tilde{p}(z) q(z'|z)} \right) \\
                   &= \text{min} \ ( p(z) q(z'|z) , p(z') q(z|z')) \\
                   &= \text{min} \ ( p(z') q(z|z') , p(z) q(z'|z)) \\
                   &=  p(z') q(z|z') \text{min} \left(1 , \frac{p(z) q(z'|z)}{p(z') q(z|z')}\right) \\
                   &=  p(z') q(z|z') \text{min} \left(1 , \frac{\tilde{p}(z) q(z'|z)}{\tilde{p}(z') q(z|z')}\right)\\
                   &= p(z') q(z|z') A(z|z') \\
                   &= p(z') T(z', z)
    \end{align*}
  \end{proof}
\end{frame}

\subsection{Gibbs Sampling}
\begin{frame}{Gibbs Sampling}
  \begin{itemize}
  \item   Metropolis-Hastings algorithm can be inefficient if proposal distribution is not chosen properly, as seen in demo.

    \pause
  \item   However if our target distribution is over $m$ variables and we can compute conditional distribution $p(z_m|z_{-m})$ where $z_{-m}$ denotes all variables other than $z_m$, Gibbs sampling is efficient algorithm.
  \end{itemize}



  \pause

  \begin{block}{Algorithm}
    \begin{itemize}
    \item initialize $z_i \quad \forall i \in [1,2, \dots , m]$
    \item for next step $\tau + 1$
      \begin{itemize}
      \item $z_1^{\tau+1} \sim p(z_1 | z_2^\tau, z_3^\tau, \dots, z_m^\tau)$
      \item $z_2^{\tau+1} \sim p(z_2 | z_1^{\tau+1}, z_3^\tau, \dots, z_m^\tau)$

      \item[]{$\vdots$}

      \item $z_m^{\tau+1} \sim p(z_m | z_1^{\tau+1}, z_2^{\tau+1}, \dots, z_{m-1}^{\tau+1})$
      \end{itemize}
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}[shrink]
  First we will prove that this transitions leads to stationary distribution.

  \begin{proof}
    \begin{align*}
      &  \sum_{z'}p(z') T(z', z) \\
      =& \sum_{z_i'}  \sum_{z_{-i}'} T(z', z) p(z_i'|z_{-i}') p(z_{-i}')  \\
      =& \sum_{z_i'}  T(z', z) p(z_i'|z_{-i}') p(z_{-i}') &&\text{where} \  z_{-i}' = z_{-i} \\
      =&  p(z_{-i}) \sum_{z_i'}  p(z_i|z_{-i}) p(z_i'|z_{-i}) \\
      =&  p(z_{-i})  p(z_i|z_{-i}) \sum_{z_i'}  p(z_i'|z_{-i}) \\
      =& p(z)
    \end{align*}
  \end{proof}
\end{frame}

\begin{frame}{Gibbs sampling as a special case of Metropolis-Hastings}
  Gibbs sampling is a special case of Metropolis-Hastings in which proposal distribution is univariate conditional and no proposals are rejected. Thus is more efficient than simple MH algorithm.

  \begin{proof}
    Suppose we are at about to do kth update in this iteration. Our proposal distribution is $q(z^*|z) = p(z_k^*|z_{-k})$. Let's calculate ratio of MH algorithm.

    \begin{align*}
      & \frac{p(z^*) q(z|z^*)}{p(z) q(z^*|z)} \\
      =& \frac{p(z_k^*|z_{-k}^*) p(z_{-k}^*) p(z_k|z_{-k}^*) }{p(z_k|z_{-k}) p(z_{-k}) p(z_k^*|z_{-k}) } \\
      =& 1 && \text{as} \quad z_{-k}^* = z_{-k} 
    \end{align*}
  \end{proof}

\end{frame}
\end{document}